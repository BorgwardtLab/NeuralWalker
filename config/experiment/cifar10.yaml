# @package _global_
defaults:
  - model: mamba_3L

training:
  lr: 0.002
  epochs: 100
  warmup: 5
  weight_decay: 1e-06
  batch_size: 32

random_walk:
  length: 50
  window_size: 8
  sample_rate: 0.5

model:
  global_pool: mean
